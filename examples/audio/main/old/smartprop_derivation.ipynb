{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]activate .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using .AudioInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trr = tones_with_noise(10,); nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#   tr, _ = AudioInference.generate(AudioInference.generate_scene, AudioInference.args)\n",
    "#   duration, _, sr, = AudioInference.get_args(tr)\n",
    "#   AudioInference.plot_gtg(underlying_gram(tr), duration, sr, 0, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(  underlying_gram(tr)[:, 147])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(initial_tr, weight) = generate_initial_tr(trr); nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = do_generic_inference(initial_tr, 40, (_...) -> nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "underlying_gram(tr) = AudioInference.get_retval(tr)[1]\n",
    "observed_gram(tr) = tr[:kernel => :scene]\n",
    "error_gram(tr) = observed_gram(tr) - underlying_gram(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_thresholded(img, threshold)\n",
    "  if threshold < 0\n",
    "    return img .< threshold\n",
    "  else\n",
    "    return img .> threshold\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area(((x1, y1), (x2, y2))) = (y2-y1) * (x2-x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration, _, sr, = AudioInference.get_args(tr)\n",
    "AudioInference.plot_gtg(get_thresholded(underlying_gram(trr), 25), duration, sr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(error_gram(tr), duration, sr, 0, 100)\n",
    "# AudioInference.plot_gtg(get_thresholded(sum(error_gram(tr), dims=1), 500), duration, sr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(img) = 1/maximum(img) * img\n",
    "rectprod(img) = sum(img, dims=2)*sum(img, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TONE_VOL = 43.\n",
    "TONE_COL_AVG_SUM = 600.\n",
    "TONE_COL_SUM_RANGE = (500., 700.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_changepoints(strip; threshold_frac=0.2)\n",
    "  # TODO: I could possibly be smarter by not doing abs, and looking at start vs end of regions\n",
    "  cnvd = abs.(conv(strip/maximum(strip), [-2 -1 0 1 2]))\n",
    "  changepts = []\n",
    "  threshold = maximum(cnvd) * threshold_frac\n",
    "  previdx = 0\n",
    "  for (i, val) in enumerate(cnvd)\n",
    "    if val > threshold\n",
    "      if previdx < i - 1\n",
    "        push!(changepts, i)\n",
    "      end\n",
    "      previdx = i\n",
    "    end\n",
    "  end\n",
    "  return changepts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = sum(error_gram(tr), dims=1)\n",
    "cnvd = (conv(sm/maximum(sm), [-2 -1 0 1 2]))\n",
    "AudioInference.plot_gtg(cnvd, duration, sr, -5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxval = maximum(cnvd)\n",
    "findall(cnvd .> maxval * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changepts = []\n",
    "threshold = maxval * 0.2\n",
    "previdx = 0\n",
    "for (i, val) in enumerate(cnvd)\n",
    "  if val > threshold\n",
    "    if previdx < i - 1\n",
    "      push!(changepts, i)\n",
    "    end\n",
    "    previdx = i\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changepoints = get_changepoints(error_gram(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st, nd = changepoints[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = normalize(sum(@view(error_gram(tr)[:, changepoints[2]:changepoints[3]]), dims=2))\n",
    "AudioInference.plot_gtg(col, duration, sr, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(get_thresholded(col, 0.1), duration, sr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv(get_thresholded(col, 0.1), [1,0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_regions(col)\n",
    "  regions = []\n",
    "  start = nothing\n",
    "  last_was_true = false\n",
    "  for i=1:length(col)\n",
    "    if col[i]>0\n",
    "      if !last_was_true\n",
    "        start = i\n",
    "      end\n",
    "      last_was_true = true\n",
    "    else\n",
    "      if last_was_true\n",
    "        push!(regions, (start, i))\n",
    "        start = nothing\n",
    "      end\n",
    "      last_was_true = false\n",
    "    end\n",
    "  end\n",
    "  return regions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_regions(get_thresholded(col, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Tones\n",
    "  regions::Vector{Tuple{Int, Int}}\n",
    "end\n",
    "function analyze_col(col)\n",
    "  thresholded = get_thresholded(col, 0.1)\n",
    "  regions = get_regions(col)\n",
    "  is_noise = sum(((st,nd),) -> nd-st, regions) > length(thresholded)/*0.7\n",
    "  if is_noise\n",
    "    analyze_noise(col)\n",
    "  else\n",
    "    analyze_tones(col, regions)\n",
    "  end\n",
    "end\n",
    "function analyze_noise(col)\n",
    "  return (:noise, sum(col)/length(col))\n",
    "end\n",
    "function analyze_tones(col, regions)\n",
    "  \n",
    "  return (:tones, [(x+y)/2 for (x,y) in regions])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_THRESHOLD = 0.1\n",
    "REGION_WIDTH = 5\n",
    "HRW = Int(floor(REGION_WIDTH/2))\n",
    "\n",
    "function get_changepoints(img)\n",
    "  vals = normalize(sum(img, dims=1))\n",
    "  filter = [-2 -1 0 1 2]\n",
    "  convd = [filter*(@view vals[x:x+4]) for x=1:length(vals)-5]\n",
    "  return findall(x -> (x[1]) > 0.3, convd)\n",
    "end\n",
    "\n",
    "# function get_vertical_bars(img)\n",
    "#   vals = sum(img, dims=1)\n",
    "#   maxval = maximum(vals)\n",
    "#   threshold = STRIP_THRESHOLD * maxval\n",
    "#   strips = []\n",
    "# #   start = 1\n",
    "# #   for x=2:length(vals)\n",
    "# #     if (vals[x]-vals[x-1]) > \n",
    "# #   end\n",
    "  \n",
    "  \n",
    "  \n",
    " \n",
    "  \n",
    "#   stripsum = sum(vals[1:REGION_WIDTH])\n",
    "#   start = 1\n",
    "#   for x=(HRW + 2):length(vals)-HRW\n",
    "#     stripsum += sum(vals[x+HRW])\n",
    "#     stripmean = stripsum/(x-start + 1)\n",
    "#     region_sum = sum(vals[x-HRW:x+HRW])\n",
    "    \n",
    "#     if abs(region_sum/REGION_WIDTH - stripmean) > threshold\n",
    "#       push!(strips, (2*start/198, 2*x/198))\n",
    "#       start = x\n",
    "#       stripsum = sum(vals[x])\n",
    "#     end\n",
    "#   end\n",
    "#   return strips\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_changepoints(underlying_gram(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "58 * 2/198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ImageMorphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = component_boxes(label_components(get_thresholded(get_error_gram(tr), 0.6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findall(x -> x > 100, area.(boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(AudioInference.get_retval(tr)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function draw_rect!(img, ((x1, y1), (x2, y2)); color=100)\n",
    "  for x=x1:x2\n",
    "    img[x, y1] = color\n",
    "    img[x, y2] = color\n",
    "  end\n",
    "  for y=y1:y2\n",
    "    img[x1, y] = color\n",
    "    img[x2, y] = color\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vis_wav_with_rectangles(tr, rects)\n",
    "  duration, _, sr, = AudioInference.get_args(tr)\n",
    "  gram, scene_wave, = AudioInference.get_retval(tr)\n",
    "  gram = copy(gram)\n",
    "  for rect in rects\n",
    "    draw_rect!(gram, rect)\n",
    "  end\n",
    "  AudioInference.plot_gtg(gram, duration, sr, 0, 100)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_wav_with_rectangles(tr, [box for box in boxes if area(box) > 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration, _, sr, = AudioInference.get_args(tr)\n",
    "AudioInference.plot_gtg(get_thresholded(get_error_gram(tr), 10), duration, sr, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do scans of horizontal strips the width of a tone up and down the image, checking which ones seem to get some good overlap.  These are frequencies at which we need to add/delete tones.  We can then look at bounding rectangles within the sub-image represented by that strip to help figure out the right start/endtime.  We could also just average the vertical part in that rectangle, and then use some 1d algorithm.\n",
    "\n",
    "Likewise, we can do scans of vertical strips left&right to find where to add/delete noise.  In this direction, we don't have fixed widths (since we don't know the noise duration).  For this, we could first scan with a 1-pixel strip, saving for each pixel the total overlap or just 1/0 depending whether it seems like a noise pixel.  We can then just look at connected components of the resulting horizontal strip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(get_thresholded(underlying_gram(tr), 10), duration, sr, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using .AudioInference: AudioSource, choicemap, generate_scene, plot_gtg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_noise_sum(tr, spot=Int(198/2))\n",
    "  sum(underlying_gram(tr)[:, spot])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = choicemap(\n",
    "  (:kernel => :n_tones, 1),\n",
    "  (:world => :waves => AudioSource(1) => :is_noise, true),\n",
    "  (:world => :waves => AudioSource(1) => :amp, 25.),\n",
    "  (:world => :waves => AudioSource(1) => :duration, 0.5),\n",
    "  (:world => :waves => AudioSource(1) => :onset, 0.75)\n",
    ")\n",
    "t, _ = AudioInference.generate(AudioInference.generate_scene, AudioInference.args, constraints)\n",
    "duration, _, sr, = AudioInference.get_args(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_constraints(amp) = choicemap(\n",
    "  (:kernel => :n_tones, 1),\n",
    "  (:world => :waves => AudioSource(1) => :is_noise, true),\n",
    "  (:world => :waves => AudioSource(1) => :amp, amp),\n",
    "  (:world => :waves => AudioSource(1) => :duration, 0.5),\n",
    "  (:world => :waves => AudioSource(1) => :onset, 0.75)\n",
    ")\n",
    "get_tr(amp) = AudioInference.generate(AudioInference.generate_scene, AudioInference.args, get_constraints(amp))[1]\n",
    "amps = 2:100\n",
    "sums = map(get_noise_sum ∘ get_tr, amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot(amps, sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(underlying_gram(t), duration, sr, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tone_constraints(erb) = choicemap(\n",
    "  (:kernel => :n_tones, 1),\n",
    "  (:world => :waves => AudioSource(1) => :is_noise, false),\n",
    "  (:world => :waves => AudioSource(1) => :erb, erb),\n",
    "  (:world => :waves => AudioSource(1) => :duration, 0.5),\n",
    "  (:world => :waves => AudioSource(1) => :onset, 0.75)\n",
    ")\n",
    "get_tone_tr(erb) = AudioInference.generate(AudioInference.generate_scene, AudioInference.args, get_tone_constraints(erb))[1]\n",
    "amps = 0.4:0.5:37.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(underlying_gram(get_tone_tr(12)), duration, sr, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(underlying_gram(get_tone_tr(12))[1:64, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get audiograms from traces\n",
    "underlying_gram(tr) = AudioInference.get_retval(tr)[1]\n",
    "observed_gram(tr) = tr[:kernel => :scene]\n",
    "error_gram(tr) = observed_gram(tr) - underlying_gram(tr)\n",
    "\n",
    "# threshold an image by the given value as a fraction of the max val in the image\n",
    "function get_thresholded(img, threshold)\n",
    "    threshold = threshold * maximum(img)\n",
    "    if threshold < 0\n",
    "        return img .< threshold\n",
    "    else\n",
    "        return img .> threshold\n",
    "    end\n",
    "end\n",
    "\n",
    "# normalize an image so the max value is 1 and min is 0\n",
    "normalize(img) = 1/(maximum(img) - minimum(img)) * img\n",
    "\n",
    "# given a strip (row vector), estimates where there are \"changepoints\" from\n",
    "# a region of one intensity to another\n",
    "function get_changepoints(strip; threshold_frac=0.2)\n",
    "    # TODO: I could possibly be smarter by not doing abs, and looking at start vs end of regions\n",
    "    cnvd = abs.(conv(strip/maximum(strip), [-2 -1 0 1 2]))\n",
    "    changepts = []\n",
    "    threshold = maximum(cnvd) * threshold_frac\n",
    "    previdx = 0\n",
    "    for (i, val) in enumerate(cnvd)\n",
    "        if val > threshold\n",
    "            if previdx < i - 1\n",
    "                push!(changepts, i)\n",
    "            end\n",
    "            previdx = i\n",
    "        end\n",
    "    end\n",
    "    return changepts\n",
    "end\n",
    "\n",
    "# given a column bitvector, returns the connected regions\n",
    "# format: [(a, b), (c, d), (e, f), ...]\n",
    "function get_regions(col)\n",
    "    regions = []\n",
    "    start = nothing\n",
    "    last_was_true = false\n",
    "    for i=1:length(col)\n",
    "        if col[i] > 0\n",
    "            if !last_was_true\n",
    "                start = i\n",
    "            end\n",
    "            last_was_true = true\n",
    "        else\n",
    "            if last_was_true\n",
    "                push!(regions, (start, i-1))\n",
    "                start = nothing\n",
    "            end\n",
    "            last_was_true = false\n",
    "        end\n",
    "    end\n",
    "    if last_was_true\n",
    "      push!(regions, (start, length(col)))\n",
    "    end\n",
    "    return regions\n",
    "end\n",
    "\n",
    "# given a column from one horizontal region of the soundwave,\n",
    "# this approximately determines whether it's a noise or a tone,\n",
    "# and the volume if it is a noise / freq if it is a tone\n",
    "function analyze_col(col, width)\n",
    "    thresholded = get_thresholded(col, 0.1)\n",
    "    regions = get_regions(thresholded)\n",
    "    is_noise = length(regions) > 0 && sum(nd-st for (st, nd) in regions) > length(thresholded)/0.7\n",
    "    if is_noise\n",
    "        analyze_noise(col, width)\n",
    "    else\n",
    "        analyze_tones(col, regions)\n",
    "    end\n",
    "end\n",
    "\n",
    "# I derived this formula by analyzing the generated\n",
    "# noises at different amp values:\n",
    "noise_amp_for_col(col) = 1054 + 64*sum(col)\n",
    "\n",
    "function analyze_noise(col, width)\n",
    "    return (:noise, noise_amp_for_col(col/width))\n",
    "end\n",
    "function analyze_tones(col, regions)\n",
    "    # TODO: how to interpret tone values as erbs?\n",
    "    return (:tones, [(x+y)/2 for (x,y) in regions])\n",
    "end\n",
    "\n",
    "### get_analyzed_img_sections ###\n",
    "function get_analyzed_audiogram_sections(gram)\n",
    "    changepoints = get_changepoints(normalize(sum(gram, dims=1)))\n",
    "    noises = []\n",
    "    tones = []\n",
    "    for i=1:length(changepoints)-1\n",
    "        region = (changepoints[i], changepoints[i+1])\n",
    "        col = sum(@view(gram[:, region[1]:region[2]]), dims=2)\n",
    "        (typ, params) = analyze_col(col, region[2] - region[1])\n",
    "        if typ === :noise\n",
    "            push!(noises, (region, params))\n",
    "        else\n",
    "            for mean in params\n",
    "                push!(tones, (region, mean))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return (noises, tones)\n",
    "end\n",
    "function analyze_underlying_gram(tr)\n",
    "    err = underlying_gram(tr)\n",
    "    pos = map(x -> x > 0 ? x : 0, err)\n",
    "    # neg = map(x -> x < 0 ? x : 0, err)\n",
    "    (posnoises, postones) = get_analyzed_audiogram_sections(pos)\n",
    "    # (negnoises, negtones) = get_analyzed_audiogram_sections(neg)\n",
    "\n",
    "    return (posnoises, postones)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = analyze_underlying_gram(get_tone_tr(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot(0:0.1:37, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[(Int(15.3 * 10)) + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
