{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]activate ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using GenWorldModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../main.jl\")\n",
    "AI = AudioInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using .AudioInference: vis_wave, generate_initial_tr, generate_scene, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth, _ = generate(AudioInference.generate_scene, args)\n",
    "println(\"Num sources: \", ground_truth[:kernel => :n_tones], \"; score = \", get_score(ground_truth))\n",
    "vis_wave(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tr, weight = AudioInference.generate_initial_tr(ground_truth, num_sources=0)\n",
    "vis_wave(initial_tr)\n",
    "println(\"Num sources: \", initial_tr[:kernel => :n_tones], \"; weight = \", weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(noises_to_add, tones_to_add) = AudioInference.analyze_errorgram(initial_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(AudioInference.error_gram(initial_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function img_with_tones(img, tones, val=100)\n",
    "  img = copy(img)\n",
    "  for tone in tones\n",
    "    add_tone_to_img!(img, tone; val=val)\n",
    "  end\n",
    "  return img\n",
    "end\n",
    "\n",
    "function add_tone_to_img!(img, tone; val=100)\n",
    "  (region, erb) = tone\n",
    "  yval = Int(floor(AudioInference.pos_for_erb_val(erb)))\n",
    "  for i=region[1]:region[2]\n",
    "    img[yval, i] = val\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function add_vert_bars(img, xvals; val=100)\n",
    "  img = copy(img)\n",
    "  for xval in xvals\n",
    "    add_vert_bar!(img, xval, val=val)\n",
    "  end\n",
    "  img\n",
    "end\n",
    "function add_vert_bar!(img, xval; val=100)\n",
    "    img[:, xval] .= val\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum(AudioInference.error_gram(initial_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioInference.plot_gtg(img_with_tones(AudioInference.error_gram(initial_tr), tones_to_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram = AudioInference.error_gram(initial_tr)\n",
    "cps = AI.get_changepoints(AI.normalize(sum(gram, dims=1)); threshold_frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(add_vert_bars(AI.error_gram(initial_tr), cps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = [\n",
    "  -0.2 -0.5 0 0.5 0.2;\n",
    "  -0.4 -1.0 0 1.0 0.4;\n",
    "  -0.2 -0.5 0 0.5 0.2\n",
    "]\n",
    "convd = AI.conv(gram, filter)\n",
    "AI.plot_gtg(1/2*convd .+ 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(convd .* (convd .> 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(abs.(convd .* (convd .< -30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startsimg = convd .< -30\n",
    "endsimg = convd .> 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(100*(startsimg - endsimg) .+ 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]add ImageMorphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ImageMorphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time component_boxes(label_components(startsimg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function draw_rect!(img, ((x1, y1), (x2, y2)); color=100)\n",
    "  for x=x1:min(x2, size(img)[1])\n",
    "    img[x, min(y1, size(img)[2])] = color\n",
    "    img[x, min(y2, size(img)[2])] = color\n",
    "  end\n",
    "  for y=y1:min(y2, size(img)[2])\n",
    "    img[min(x1, size(img)[1]), y] = color\n",
    "    img[min(x2, size(img)[1]), y] = color\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function img_with_rects(img, rects; color=100)\n",
    "  img = copy(img)\n",
    "  for rect in rects\n",
    "    draw_rect!(img, rect; color=color)\n",
    "  end\n",
    "  return img\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects = component_boxes(label_components(startsimg))\n",
    "AI.plot_gtg(img_with_rects(gram, rects[2:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct VertSegment\n",
    "  x::Int\n",
    "  ymin::Int\n",
    "  ymax::Int\n",
    "end\n",
    "startseg(((ymin, xmin), (ymax, xmax))) = VertSegment(xmin, ymin, ymax)\n",
    "endseg(((ymin, xmin), (ymax, xmax))) = VertSegment(xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function add_vert_segs(img, segs; val=100)\n",
    "  img = copy(img)\n",
    "  for seg in segs\n",
    "    add_vert_seg!(img, seg, val=val)\n",
    "  end\n",
    "  img\n",
    "end\n",
    "function add_vert_seg!(img, seg; val=100)\n",
    "    for y=seg.ymin:min(seg.ymax, size(img)[1])\n",
    "      img[y, seg.x] = val\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startrects = component_boxes(label_components(startsimg))[2:end]\n",
    "endrects = component_boxes(label_components(endsimg))[2:end]\n",
    "startsegs = map(startseg, startrects)\n",
    "endsegs = map(startseg, endrects)\n",
    "\n",
    "img_with_starts_ends = add_vert_segs( add_vert_segs(gram, startsegs, val=100), endsegs, val=-100 )\n",
    "\n",
    "AI.plot_gtg(1/2*img_with_starts_ends .+ 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "could_be_noise(seg) = seg.ymax - seg.ymin > 64/3\n",
    "could_be_tone(seg) = let diff = seg.ymax - seg.ymin; diff >= 5 && diff <= 64/2; end\n",
    "function possible_tone_noise_starts(startsegs)\n",
    "  noisesegs = []\n",
    "  tonesegs = []\n",
    "  for seg in startsegs\n",
    "    if could_be_noise(seg)\n",
    "      push!(noisesegs, seg)\n",
    "    end\n",
    "    if could_be_tone(seg)\n",
    "      push!(tonesegs, seg)\n",
    "    end\n",
    "  end\n",
    "  return (noisesegs, tonesegs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisesegs, tonesegs = possible_tone_noise_starts(startsegs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_endsegs(startseg, endsegs) = (seg for seg in endsegs if could_end(startseg, seg))\n",
    "function could_end(startseg, endseg)\n",
    "    endseg.x > startseg.x && overlap((startseg.ymin, startseg.ymax), (endseg.ymin, endseg.ymax)) > 0\n",
    "end\n",
    "function overlap((a, b), (c, d))\n",
    "    if a > c\n",
    "        return overlap((c, d), (a, b))\n",
    "    end\n",
    "    if b < c\n",
    "        return 0\n",
    "    end\n",
    "    if d < b\n",
    "        return (d - c) + 1\n",
    "    end\n",
    "    return b - c + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(possible_endsegs(startsegs[2], endsegs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function tonerect(startseg, endseg)\n",
    "  if endseg.ymax - endseg.ymin > 50\n",
    "      return ((startseg.ymin, startseg.x), (startseg.ymax, endseg.x))\n",
    "  end\n",
    "  ymin = min(startseg.ymin, endseg.ymin)\n",
    "  ymax = max(startseg.ymax, endseg.ymax)\n",
    "  return ((ymin, startseg.x), (ymax, endseg.x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function noiserect(startseg, endseg)\n",
    "  return ((1, startseg.x), (64, endseg.x))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segpairs(startsegs) = Iterators.flatten(\n",
    "  ((startseg, endseg) for endseg in possible_endsegs(startseg, endsegs))\n",
    "  for startseg in startsegs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rects = [map(x -> tonerect(x...), segpairs(tonesegs))...,  map(x -> noiserect(x...), segpairs(noisesegs))...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(img_with_rects(gram, rects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../detector.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(img_with_rects(gram, Iterators.flatten(Detector.get_noise_tone_rects(gram; threshold=0.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth2, _ = generate(AudioInference.generate_scene, args, choicemap((:kernel => :n_tones, 4)))\n",
    "println(\"Num sources: \", ground_truth2[:kernel => :n_tones], \"; score = \", get_score(ground_truth2))\n",
    "vis_wave(ground_truth2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tr, weight = AudioInference.generate_initial_tr(ground_truth2, num_sources=0)\n",
    "gram = AI.error_gram(initial_tr)\n",
    "AI.plot_gtg(img_with_rects(gram, Iterators.flatten(Detector.get_noise_tone_rects(gram; threshold=0.4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
