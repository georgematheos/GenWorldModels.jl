{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "]activate ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen\n",
    "using GenWorldModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../main.jl\")\n",
    "AI = AudioInference\n",
    "using .AI: AudioSource, gammatonegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../worldmodel/smart_birth_death.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"plotting_utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth, _ = generate(AI.generate_scene, AI.args, choicemap((:kernel => :n_tones, 3)))\n",
    "initial_tr, weight = AI.generate_initial_tr(ground_truth, num_sources=0)\n",
    "gram = AI.error_gram(initial_tr)\n",
    "AI.plot_gtg(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tr, weight = AI.generate_initial_tr(ground_truth, num_sources=0)\n",
    "\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize(\"chociemap.txt\", get_choices(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOBEL_FILTER = [\n",
    "    -0.2 -0.5 0 0.5 0.2;\n",
    "    -0.4 -1.0 0 1.0 0.4;\n",
    "    -0.2 -0.5 0 0.5 0.2\n",
    "]\n",
    "edges = Detector.conv(error_gram(inferred_tr), SOBEL_FILTER)\n",
    "AI.plot_gtg(edges/2 .+ 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_SOBEL_FILTER = [\n",
    "      -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "      -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "    -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "    -0.4  -0.4 -0.4 -1.0 0 1.0 0.4 0.4 0.4;\n",
    "    -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "      -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "    -0.2 -0.2 -0.2 -0.5 0 0.5 0.2 0.2 0.2;\n",
    "]\n",
    "edges2 = Detector.conv(error_gram(inferred_tr), BIG_SOBEL_FILTER)\n",
    "AI.plot_gtg(edges2/2 .+ 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_likely_start_end(tr, ch)\n",
    "    eg = error_gram(tr)\n",
    "    (ysize, xsize) = size(eg)\n",
    "\n",
    "    st = Int(floor(ch[:onset] * xsize))\n",
    "    nd = Int(floor((min(ch[:onset] + ch[:duration], 1)) * xsize))\n",
    "\n",
    "    if ch[:is_noise]\n",
    "        miny, maxy = 1, ysize\n",
    "    else\n",
    "        meany = Int(floor(pos_for_erb_val(ch[:erb])))\n",
    "        miny, maxy = meany - TONESIZE/2, meany + TONESIZE/2\n",
    "    end\n",
    "\n",
    "    eg_region = eg[miny:maxy, st:nd]\n",
    "    \n",
    "    (startsegs, endsegs) = Detector.get_start_end_segs(eg_region)\n",
    "\n",
    "    selected_startseg = startsegs[argmax(map(seglength, startsegs))]\n",
    "  selected_endseg = endsegs[argmax(map(seglength, endsegs))]\n",
    "\n",
    "    (st + selected_endseg.x, st + selected_startseg.x)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ept, spt) = get_likely_start_end(inferred_tr, get_subtree(get_choices(inferred_tr), :world => :waves => AudioSource(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(add_vert_bars(AI.error_gram(inferred_tr), [ept, spt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in ssegs if s.ymax - s.ymin > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s for s in esegs if s.ymax - s.ymin > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subtree(get_choices(inferred_tr), :kernel => :n_tones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(100 * (edges2 .< minimum(edges2) * 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(100 * (edges2 .> maximum(edges2) * 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = Detector.get_detected_sources(gram; threshold=0.5, scenelength=2.)\n",
    "AI.plot_gtg(img_with_source_rects(gram, (sources), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trs = []\n",
    "for _=1:10\n",
    "  acc = false\n",
    "  while !acc\n",
    "    tr, acc = mh(initial_tr, smart_birth_death_mh_kern; check=true)\n",
    "      push!(trs, tr)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr in trs\n",
    "  AI.plot_gtg(underlying_gram(tr))\n",
    "  AI.PyPlot.figure()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Detector.MIN_SOURCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../worldmodel/inference2.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_tr = drift_smartsmbd_inference(initial_tr, 10)\n",
    "nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_inferred_tr = drift_smartsmbd_inference(inferred_tr, 10)\n",
    "isnew = new_inferred_tr != inferred_tr\n",
    "inferred_tr = new_inferred_tr\n",
    "isnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(observed_gram(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  score(inferred_tr, Death(\n",
    "      source_type(inferred_tr, i), i)\n",
    "    )\n",
    "  for i=1:num_sources(inferred_tr)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(inferred_tr, Death(tone, 2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(inferred_tr, Death(tone, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, acc = metropolis_hastings(inferred_tr, smart_birth_death_mh_kern; check=false, logscores=true, logfwdchoices=true)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subtree(get_choices(inferred_tr), :world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function test_drift(idx)\n",
    "  total = 0\n",
    "  for _=1:1\n",
    "    inf_tr, acc = mh(inferred_tr, start_drift, (idx,))\n",
    "    if acc\n",
    "      total += 1\n",
    "    end\n",
    "  end\n",
    "  return total/1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_drift(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, weight = generate(onset_drift, (inferred_tr, 4))\n",
    "get_choices(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it, uwt, _, _ = update(inferred_tr, AI.args, map(_ -> NoChange(), AI.args), get_choices(tr))\n",
    "uwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(observed_gram(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_tr = inferred_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(error_gram(inferred_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = Detector.get_detected_sources(error_gram(inferred_tr))\n",
    "[source for source in sources if score(error_gram(tr), source) > exp(-0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(img_with_source_rects(observed_gram(inferred_tr), (sources), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum(map(s -> score(error_gram(tr), s), sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[source for source in sources if source.is_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[s => score(observed_gram(tr), s) for s in sources if s.is_noise]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_to_score = [s => score(observed_gram(tr), s) for s in sources]\n",
    "filtered = [s => sc for (s, sc) in source_to_score if sc > exp(1.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(img_with_source_rects(gram, map(x -> x[1], filtered), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    score(gram, s::Source; threshold=0.5)\n",
    "\n",
    "The score of a birth action gives a heuristic estimate of how \"good\" it is to add this object.\n",
    "This score is calculated by inspecting the rough rectangle in which the tone/noise will be placed,\n",
    "and counting how many pixels in the errorgram are \"on\", minus how many are off.  We normalize this by dividing\n",
    "by the rectangle area, to get a measure of \"fraction_improvement\"\n",
    "(what fraction of the area is an improvement, minus the fraction that makes things worse).\n",
    "The score is e^(λ * improvement).\n",
    "\"\"\"\n",
    "function score(gram, s::Detector.Source; threshold=0.5)\n",
    "    ((miny, minx), (maxy, maxx)) = rect_for_source(gram, s, 2)\n",
    "    gram = @view gram[miny:maxy, minx:maxx]\n",
    "    maxval = maximum(gram)\n",
    "    greater_than_threshold = gram .> maxval * threshold\n",
    "    less_than_threshold = gram .< maxval * threshold\n",
    "    area = (maxx - minx + 1) * (maxy - miny + 1)\n",
    "    improvement = (sum(greater_than_threshold) - sum(less_than_threshold))/area\n",
    "    if improvement > 1\n",
    "      println(\"greater_than_threshold = \")\n",
    "      display(greater_than_threshold)\n",
    "      println(\"sum of greater_than_threshold = \", sum(greater_than_threshold))\n",
    "      println(\"sum of less_than_threshold = \", sum(less_than_threshold))\n",
    "      println(\"area = \", area)\n",
    "      println(\"rect: \", ((miny, minx), (maxy, maxx)))\n",
    "      @assert false\n",
    "    end\n",
    "    return exp(λ * improvement)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, acc = mh(initial_tr, smart_birth_death_mh_kern; check=true)\n",
    "println(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "for _=1:20\n",
    "  tr, acc = mh(tr, smart_birth_death_mh_kern; check=true)\n",
    "  total_acc += acc\n",
    "end\n",
    "println(\"Total number accepted: \", total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function iterated_birth_death(tr, bd_kernel, accumulated_weight=0; check=true)\n",
    "  (new_tr, weight) = bd_kernel(tr; check=check)\n",
    "  accumulated_weight += weight\n",
    "  stop_prob = exp(accumulated_weight) > 0.5 ? 0.99 : 0.25\n",
    "  if bernoulli(stop_prob)\n",
    "    return (new_tr, accumulated_weight)\n",
    "  else\n",
    "    return iterated_birth_death(new_tr, bd_kernel, accumulated_weight; check=check)\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc = 0\n",
    "for _=1:20\n",
    "  new_tr, weight = iterated_birth_death(tr, smart_birth_death_mh_kern; check=true)\n",
    "  if bernoulli(weight)\n",
    "    total_acc += 1\n",
    "    tr = new_tr\n",
    "  end\n",
    "end\n",
    "println(\"Total number accepted: \", total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(new_tr, weight) = iterated_birth_death(tr, smart_birth_death_mh_kern; check=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(new_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(proptr, _) = generate(smart_birth_death_proposal, (tr,))\n",
    "get_choices(proptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess(smart_birth_death_proposal, (tr,), get_choices(proptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtr, weight, _, _ = update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subtree(get_choices(tr), :world => :waves => AudioSource(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(underlying_gram(ground_truth)[:, 5]) - 1054)/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subtree(get_choices(ground_truth), :world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proptr, wt = generate(smart_birth_death_proposal, (initial_tr,), choicemap((:do_smart_birth, false)))\n",
    "get_choices(proptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_pass_results = GenWorldModels.run_first_pass(smart_birth_death_involution, tr, proptr)\n",
    "first_pass_results.update_spec.subspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtr, wt, _, _ = update(tr, get_args(initial_tr),\n",
    "map(_ -> NoChange(), get_args(initial_tr)),\n",
    "first_pass_results.update_spec,\n",
    "invert(first_pass_results.reverse_regenerated));\n",
    "wt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_subtree(get_choices(newtr), :world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(underlying_gram(newtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI.plot_gtg(observed_gram(newtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
